__author__ = 'Administrator'
'''什么是分布式爬虫
分布式爬虫就是多台计算机上都安装爬虫程序，重点是联合采集。单机爬虫就是只在一台计算机上的爬虫。
其实搜索引擎都是爬虫，负责从世界各地的网站上爬取内容，当你搜索关键词时就把相关的内容展示给你，只不过他们那都是灰常大的爬虫，爬的内容量也超乎想象，也就无法再用单机爬虫去实现，而是使用分布式了，一台服务器不行，我来1000台。我这么多分布在各地的服务器都是为了完成爬虫工作，彼此得通力协作才行啊，于是就有了分布式爬虫
单机爬虫的问题：
一台计算机的效率问题
IO 的吞吐量，传输速率也有限
多爬虫问题

多爬虫要实现数据共享
比如说一个爬取了某个网站，下载了哪些内容，其他爬虫要知道，以避免重复爬取等很多问题，所以要实现数据共享
在空间上不同的多台机器，可以成为分布式

多爬虫条件：
需要共享队列
去重，让多个爬虫不爬取其他爬虫爬取过的爬虫
理解分布式爬虫：
假设上万的 url 需要爬取，有 100 多个爬虫，分布在全国不同的城市
url 被分给不同的爬虫，但是不同爬虫的效率又是不一样的，所以说共享队列，共享数据，让效率高的爬虫多去做任务，而不是等着效率低的爬虫
Redis
Redis 是完全开源免费的，遵守BSD协议，是一个高性能的 key-value 数据库
内存数据库，数据存放在内存
同时可以落地保存到硬盘
可以去重
可以把 Redis 理解成一共 dict，set，list 的集合体
Redis 可以对保存的内容进行生命周期
Redis 教程：Redis 教程 - 菜鸟教程
内容保存数据库

MongoDB，运行在内存，数据保存在硬盘
MySQL
等等
安装 scrapy_redis
1.打开【cmd】
2.进入使用的 Anaconda 环境
3.使用 pip 安装
4.操作截图'''
